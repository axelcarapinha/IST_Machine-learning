{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1 / 2) Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) One iteration of EM clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for x1:\n",
      "  Likelihood P(x | C=1): 0.159155\n",
      "  Likelihood P(x | C=2): 0.002915\n",
      "  Joint P(C=1, x): 0.095493\n",
      "  Joint P(C=2, x): 0.001166\n",
      "\n",
      "Results for x2:\n",
      "  Likelihood P(x | C=1): 0.002915\n",
      "  Likelihood P(x | C=2): 0.159155\n",
      "  Joint P(C=1, x): 0.001749\n",
      "  Joint P(C=2, x): 0.063662\n",
      "\n",
      "Results for x3:\n",
      "  Likelihood P(x | C=1): 0.126929\n",
      "  Likelihood P(x | C=2): 0.015543\n",
      "  Joint P(C=1, x): 0.076157\n",
      "  Joint P(C=2, x): 0.006217\n",
      "\n",
      "Maximum Likelihood P(x | C=1): 0.159155\n",
      "Maximum Likelihood P(x | C=2): 0.159155\n",
      "Maximum Joint P(C=1, x): 0.095493\n",
      "Maximum Joint P(C=2, x): 0.063662\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#\n",
    "# Preparation\n",
    "#\n",
    "observations = {\n",
    "    'x1': np.array([1, 1]),\n",
    "    'x2': np.array([-1, -1]),\n",
    "    'x3': np.array([0.5, 0.55])\n",
    "}\n",
    "\n",
    "# Cluster parameters (\"mu\" = mean, \"sigma\" = covariance matrix)\n",
    "mu1 = np.array([1, 1]) \n",
    "sigma1 = np.array([[1, 0], [0, 1]])\n",
    "mu2 = np.array([-1, -1])\n",
    "sigma2 = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "P_C1 = 0.6\n",
    "P_C2 = 0.4\n",
    "\n",
    "def multivariate_normal_likelihood(x, mu, sigma):\n",
    "    d = len(x)\n",
    "    coeff = 1 / ((2 * np.pi) ** (d / 2) * np.linalg.det(sigma) ** 0.5)\n",
    "    exponent = -0.5 * (x - mu).T @ np.linalg.inv(sigma) @ (x - mu)\n",
    "    return coeff * np.exp(exponent)\n",
    "\n",
    "#\n",
    "# Expectation (calculating the responsibilities)\n",
    "#\n",
    "results = {}\n",
    "for name, x in observations.items():\n",
    "    likelihood_C1 = multivariate_normal_likelihood(x, mu1, sigma1)\n",
    "    likelihood_C2 = multivariate_normal_likelihood(x, mu2, sigma2)\n",
    "    \n",
    "    joint_C1 = P_C1 * likelihood_C1\n",
    "    joint_C2 = P_C2 * likelihood_C2\n",
    "    \n",
    "    results[name] = {\n",
    "        'likelihood_C1': likelihood_C1,\n",
    "        'likelihood_C2': likelihood_C2,\n",
    "        'joint_C1': joint_C1,\n",
    "        'joint_C2': joint_C2\n",
    "    }\n",
    "\n",
    "for name, res in results.items():\n",
    "    print(f\"Results for {name}:\")\n",
    "    print(f\"  Likelihood P(x | C=1): {res['likelihood_C1']:.6f}\")\n",
    "    print(f\"  Likelihood P(x | C=2): {res['likelihood_C2']:.6f}\")\n",
    "    print(f\"  Joint P(C=1, x): {res['joint_C1']:.6f}\")\n",
    "    print(f\"  Joint P(C=2, x): {res['joint_C2']:.6f}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "#\n",
    "# Maximization (updating the parameters considering the responsibilities)\n",
    "#\n",
    "\n",
    "# Find the maximum likelihoods and joint probabilities across all observations\n",
    "max_likelihood_C1 = max(res['likelihood_C1'] for res in results.values())\n",
    "max_likelihood_C2 = max(res['likelihood_C2'] for res in results.values())\n",
    "max_joint_C1 = max(res['joint_C1'] for res in results.values())\n",
    "max_joint_C2 = max(res['joint_C2'] for res in results.values())\n",
    "\n",
    "print(f\"Maximum Likelihood P(x | C=1): {max_likelihood_C1:.6f}\")\n",
    "print(f\"Maximum Likelihood P(x | C=2): {max_likelihood_C2:.6f}\")\n",
    "print(f\"Maximum Joint P(C=1, x): {max_joint_C1:.6f}\")\n",
    "print(f\"Maximum Joint P(C=2, x): {max_joint_C2:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2 / 2) Software Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) EM vs k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics, datasets, tree, cluster\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "NUM_CLUSTERS = 3\n",
    "METRIC = 'euclidean'\n",
    "\n",
    "# (0.) load the data\n",
    "data = datasets.load_wine()\n",
    "X,y= data.data, data.target\n",
    "\n",
    "# (1.1) k-means \n",
    "kmeans_algo = cluster.KMeans(n_clusters=NUM_CLUSTERS,algorithm='lloyd',init='random',n_init=1)\n",
    "\n",
    "# (1.2) Fit the model to the data\n",
    "kmeans_model = kmeans_algo.fit(X)\n",
    "\n",
    "# (1.3) Silhouette score\n",
    "kmeans_model.cluster_centers_\n",
    "labels = kmeans_model.labels_\n",
    "silhouette_kmeans = metrics.silhouette_score(X, labels, metric=METRIC)\n",
    "print(f\"silhouette (k-means): {silhouette_kmeans}\")\n",
    "\n",
    "# (2.1) EM clusterin - Learn EM with multivariate Gaussian assumption (with 1 single run with starting point)\n",
    "em_algo = GaussianMixture(n_components=NUM_CLUSTERS, covariance_type='full',n_init=1) \n",
    "em_model = em_algo.fit(X)\n",
    "\n",
    "# (2.2) Silhouette score\n",
    "labels_em= em_model.predict(X)\n",
    "silhouette_emclustering = metrics.silhouette_score(X, labels_em, metric=METRIC)\n",
    "print(f\"silhouette (EM clustering): {silhouette_emclustering}\")\n",
    "\n",
    "# (3.) Comparing k-means with EM clustering (for wine dataset)\n",
    "comparison_result = \"k-means\" if silhouette_kmeans > silhouette_emclustering else \"EM clustering\"\n",
    "print(f\"{comparison_result} is better!\")\n",
    "\n",
    "# (4.) Plot\n",
    "plt.scatter(X[:, 0], X[:, 1], X[: ,2], c=labels_em)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) PCA with 2 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics, datasets, tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "NUM_COMPONENTS = 2\n",
    "\n",
    "# (1.) load the data\n",
    "data = datasets.load_wine()\n",
    "X,y= data.data, data.target\n",
    "\n",
    "# (2.) learn the transformation (components as linear combination of features)\n",
    "pca = PCA(n_components=NUM_COMPONENTS)\n",
    "X_pca = pca.fit(X).transform(X)\n",
    "print(\"Components:\\n\",pca.components_)\n",
    "\n",
    "# (3.) Let's plot it!\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1],c=y)\n",
    "plt.show()\n",
    "'''\n",
    "The values overlap, so the three classes cannot be separated \n",
    "(the variance is not sufficient to perform classification in this dataset).\n",
    "'''\n",
    "\n",
    "# Extra (3D representation)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], c=y)\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(X_pca[:,0], X_pca[:,1],c=y)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Clustering from PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, cluster, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "NUM_COMPONENTS = 2\n",
    "NUM_CLUSTERS = 3\n",
    "METRIC = 'euclidean'\n",
    "\n",
    "# (1.1) load the data\n",
    "data = datasets.load_wine()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# (1.2) learn the transformation (components as linear combination of features)\n",
    "pca = PCA(n_components=NUM_COMPONENTS)\n",
    "X_pca = pca.fit(X).transform(X)\n",
    "INPUT_DATASET = X_pca  # using previous dataset\n",
    "# INPUT_DATASET = X\n",
    "\n",
    "# (2.1) learning b) returned dataset (k-means)\n",
    "kmeans_algo = cluster.KMeans(n_clusters=NUM_CLUSTERS, algorithm='lloyd', init='random', n_init=1)\n",
    "kmeans_model = kmeans_algo.fit(INPUT_DATASET)  # using returned dataset from PCA\n",
    "\n",
    "kmeans_model.cluster_centers_\n",
    "labels = kmeans_model.labels_\n",
    "silhouette_kmeans = metrics.silhouette_score(INPUT_DATASET, labels, metric=METRIC)\n",
    "print(f\"Silhouette (k-means): {silhouette_kmeans}\")\n",
    "\n",
    "plt.scatter(INPUT_DATASET[:, 0], INPUT_DATASET[:, 1], c=labels)\n",
    "plt.show()\n",
    "\n",
    "# (2.2) learning b) returned dataset (EM clustering)\n",
    "em_algo = GaussianMixture(n_components=NUM_CLUSTERS, covariance_type='full', n_init=1)\n",
    "em_model = em_algo.fit(INPUT_DATASET)\n",
    "\n",
    "labels_em = em_model.predict(INPUT_DATASET)\n",
    "silhouette_emclustering = metrics.silhouette_score(INPUT_DATASET, labels_em, metric=METRIC)\n",
    "print(f\"Silhouette (EM clustering): {silhouette_emclustering}\")\n",
    "\n",
    "# (3.) Scatter plot (EM clustering)\n",
    "plt.scatter(INPUT_DATASET[:, 0], INPUT_DATASET[:, 1], c=labels_em)\n",
    "plt.show()\n",
    "\n",
    "# (3.) Comparing results (k-means VS EM clustering)\n",
    "# 3. Comparing k-means with EM clustering (for wine dataset)\n",
    "comparison_result = \"k-means\" if silhouette_kmeans > silhouette_emclustering else \"EM clustering\"\n",
    "print(f\"{comparison_result} is better!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) PCA mapped data VS not mapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics, datasets, cluster\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Flags to control the behaviours of the calculations\n",
    "PCA_USED = True\n",
    "NUM_CLUSTERS = 2\n",
    "METRIC = 'euclidean'\n",
    "NUM_COMPONENTS = 2\n",
    "\n",
    "# Wrapper function (avoid repeated code)\n",
    "def plot_data(input_data, c, title, label, PCA_USED):\n",
    "    plt.scatter(input_data[:, 0], input_data[:, 1], c=c, cmap='plasma', marker='o', label=label)\n",
    "    title += \" on PCA-transformed Data\" if PCA_USED else \" without PCA\"\n",
    "    plt.title(title)\n",
    "    if PCA_USED:\n",
    "        plt.xlabel('Component 1')\n",
    "        plt.ylabel('Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# (1.1) load the data\n",
    "data = datasets.load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "if not PCA_USED:   # as untreated data\n",
    "    INPUT_DATA = X\n",
    "else:              # PCA Transformation\n",
    "    pca = PCA(n_components=NUM_COMPONENTS)\n",
    "    X_pca = pca.fit_transform(X)  # transformed data for consistent shape\n",
    "    INPUT_DATA = X_pca\n",
    "\n",
    "# (2.1) clustering (k-means) on PCA-transformed data\n",
    "kmeans_algo = cluster.KMeans(n_clusters=NUM_CLUSTERS, algorithm='lloyd', init='random', n_init=1)\n",
    "kmeans_model = kmeans_algo.fit(INPUT_DATA)\n",
    "labels_kmeans = kmeans_model.labels_\n",
    "silhouette_kmeans = metrics.silhouette_score(INPUT_DATA, labels_kmeans, metric=METRIC)\n",
    "print(f\"Silhouette (K-means): {silhouette_kmeans}\")\n",
    "plot_data(INPUT_DATA,labels_kmeans,'k-means clustering','K-means', PCA_USED)\n",
    "\n",
    "# (2.2) EM Clustering on PCA-transformed data\n",
    "em_algo = GaussianMixture(n_components=NUM_CLUSTERS, covariance_type='full', n_init=1)\n",
    "em_model = em_algo.fit(INPUT_DATA)\n",
    "labels_em = em_model.predict(INPUT_DATA)\n",
    "silhouette_em = metrics.silhouette_score(INPUT_DATA, labels_em, metric=METRIC)\n",
    "print(f\"Silhouette (EM Clustering): {silhouette_em}\")\n",
    "plot_data(INPUT_DATA,labels_em,'EM clustering','EM', PCA_USED)\n",
    "\n",
    "# (2.3) Comparing results (K-means vs EM Clustering)\n",
    "comparison_result = \"K-means\" if silhouette_kmeans > silhouette_em else \"EM Clustering\"\n",
    "print(f\"{comparison_result} is better based on silhouette score!\")\n",
    "\n",
    "#TODO confirm that Davies' measure is NOT needed here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
